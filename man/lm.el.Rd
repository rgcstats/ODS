% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/lm_el.R
\name{lm.el}
\alias{lm.el}
\title{Calculates maximum empirical likelihood estimators for linear regression}
\usage{
lm.el(ys, xs, pi.fn, N, R = 100, tol = 1)
}
\arguments{
\item{ys}{vector of sample values of the dependent variable}

\item{xs}{matrix of covariate values (number of rows must equal n where n is length of ys).
Intercept is not assumed, so xs should contain a column of 1s if you want an intercept in the model.}

\item{pi.fn}{a function taking a single argument y and returning the probability
of selection}

\item{N}{the population size}

\item{R}{the number of simulations used in the monte carlo approximation
of the likelihood}

\item{tol}{a factor controlling error-tolerance in integration (defaults to 1)}
}
\value{
a vector containing p estimated coefficients (where p=ncol(xs)) and the
estimated error standard deviation. No variance estimates provided.
}
\description{
This function fits a linear model to complex sample data by maximum sample likelihood
}
\details{
See Krieger and Pfefferman's paper.
The dependent variable is assumed to be normally distributed.
}
\examples{
data(population_example)
lm.el(ys=sample.example$y,xs=cbind(1,sample.example$x),N=1000,
pi.fn=function(y,log=FALSE){
out <- pmin(1,0.05*sqrt(0.1+0.9*(y-5)^2/1))
if(log) return(log(out))
if(!log) return(out)})
}
